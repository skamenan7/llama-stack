---
description: |
  [Elasticsearch](https://www.elastic.co/) is a vector database provider for Llama Stack.
  It allows you to store and query vectors directly within an Elasticsearch database.
  That means you're not limited to storing vectors in memory or in a separate service.

  ## Features
  Elasticsearch supports:
  - Store embeddings and their metadata
  - Vector search
  - Full-text search
  - Fuzzy search
  - Hybrid search
  - Document storage
  - Metadata filtering
  - Inference service
  - Machine Learning integrations

  ## Usage

  To use Elasticsearch in your Llama Stack project, follow these steps:

  1. Install the necessary dependencies.
  2. Configure your Llama Stack project to use Elasticsearch.
  3. Start storing and querying vectors.

  ## Installation

  You can test Elasticsearch locally by running this script in the terminal:

  ```bash
  curl -fsSL https://elastic.co/start-local | sh
  ```

  Or you can [start a free trial](https://www.elastic.co/cloud/cloud-trial-overview?utm_campaign=llama-stack-integration) on Elastic Cloud.
  For more information on how to deploy Elasticsearch, see the [official documentation](https://www.elastic.co/docs/deploy-manage/deploy).

  ## Documentation
  See [Elasticsearch's documentation](https://www.elastic.co/docs/solutions/search) for more details about Elasticsearch in general.
sidebar_label: Remote - Elasticsearch
title: remote::elasticsearch
---

# remote::elasticsearch

## Description


[Elasticsearch](https://www.elastic.co/) is a vector database provider for Llama Stack.
It allows you to store and query vectors directly within an Elasticsearch database.
That means you're not limited to storing vectors in memory or in a separate service.

## Features
Elasticsearch supports:
- Store embeddings and their metadata
- Vector search
- Full-text search
- Fuzzy search
- Hybrid search
- Document storage
- Metadata filtering
- Inference service
- Machine Learning integrations

## Usage

To use Elasticsearch in your Llama Stack project, follow these steps:

1. Install the necessary dependencies.
2. Configure your Llama Stack project to use Elasticsearch.
3. Start storing and querying vectors.

## Installation

You can test Elasticsearch locally by running this script in the terminal:

```bash
curl -fsSL https://elastic.co/start-local | sh
```

Or you can [start a free trial](https://www.elastic.co/cloud/cloud-trial-overview?utm_campaign=llama-stack-integration) on Elastic Cloud.
For more information on how to deploy Elasticsearch, see the [official documentation](https://www.elastic.co/docs/deploy-manage/deploy).

## Documentation
See [Elasticsearch's documentation](https://www.elastic.co/docs/solutions/search) for more details about Elasticsearch in general.


## Configuration

| Field | Type | Required | Default | Description |
|-------|------|----------|---------|-------------|
| `elasticsearch_api_key` | `str \| None` | No |  | The API key for the Elasticsearch instance |
| `elasticsearch_url` | `str \| None` | No | localhost:9200 | The URL of the Elasticsearch instance |
| `persistence` | `KVStoreReference \| None` | No |  | Config for KV store backend (SQLite only for now) |
| `persistence.namespace` | `str` | No |  | Key prefix for KVStore backends |
| `persistence.backend` | `str` | No |  | Name of backend from storage.backends |

## Sample Configuration

```yaml
elasticsearch_url: ${env.ELASTICSEARCH_URL:=localhost:9200}
elasticsearch_api_key: ${env.ELASTICSEARCH_API_KEY:=}
persistence:
  namespace: vector_io::elasticsearch
  backend: kv_default
```
