version: 2
image_name: ci-tests-bedrock
apis:
  - inference
  - models
providers:
  inference:
    - provider_id: bedrock
      provider_type: remote::bedrock
      config:
        api_key: ${env.AWS_BEARER_TOKEN_BEDROCK:=replay-mode-dummy-key}
        region_name: us-west-2
storage:
  backends:
    kv_default:
      type: kv_sqlite
      db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ci-tests}/kvstore.db
    sql_default:
      type: sql_sqlite
      db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ci-tests}/sql_store.db
  stores:
    metadata:
      namespace: registry
      backend: kv_default
    inference:
      table_name: inference_store
      backend: sql_default
      max_write_queue_size: 10000
      num_writers: 4
    conversations:
      table_name: openai_conversations
      backend: sql_default
    prompts:
      namespace: prompts
      backend: kv_default
registered_resources:
  models:
    - model_id: openai.gpt-oss-20b-1:0
      provider_id: bedrock
      provider_resource_id: openai.gpt-oss-20b-1:0
      model_type: llm
      metadata:
        description: "OpenAI GPT-OSS 20B on Bedrock (us-west-2)"
  shields: []
  vector_dbs: []
  datasets: []
  scoring_fns: []
  benchmarks: []
  tool_groups: []
server:
  port: 8321
