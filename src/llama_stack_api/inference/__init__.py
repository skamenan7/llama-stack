# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the terms described in the LICENSE file in
# the root directory of this source tree.

"""Inference API protocol and models.

This module contains the Inference protocol definition.
Pydantic models are defined in llama_stack_api.inference.models.
The FastAPI router is defined in llama_stack_api.inference.fastapi_routes.
"""

# Import common types for backward compatibility
# (these were previously available from the old inference.py)
from llama_stack_api.common.content_types import InterleavedContent

# Import fastapi_routes for router factory access
from . import fastapi_routes

# Import protocol for re-export
from .api import Inference, InferenceProvider, ModelStore

# Import models for re-export
from .models import (
    AllowedToolsConfig,
    Bf16QuantizationConfig,
    ChatCompletionResponseEventType,
    CompletionRequest,
    CustomToolConfig,
    EmbeddingsResponse,
    EmbeddingTaskType,
    Fp8QuantizationConfig,
    FunctionToolConfig,
    GetChatCompletionRequest,
    GrammarResponseFormat,
    GreedySamplingStrategy,
    Int4QuantizationConfig,
    JsonSchemaResponseFormat,
    ListChatCompletionsRequest,
    ListOpenAIChatCompletionResponse,
    LogProbConfig,
    OpenAIAssistantMessageParam,
    OpenAIChatCompletion,
    OpenAIChatCompletionChunk,
    OpenAIChatCompletionContentPartImageParam,
    OpenAIChatCompletionContentPartParam,
    OpenAIChatCompletionContentPartTextParam,
    OpenAIChatCompletionMessageContent,
    OpenAIChatCompletionRequestWithExtraBody,
    OpenAIChatCompletionTextOnlyMessageContent,
    OpenAIChatCompletionToolCall,
    OpenAIChatCompletionToolCallFunction,
    OpenAIChatCompletionToolChoice,
    OpenAIChatCompletionToolChoiceAllowedTools,
    OpenAIChatCompletionToolChoiceCustomTool,
    OpenAIChatCompletionToolChoiceFunctionTool,
    OpenAIChatCompletionUsage,
    OpenAIChatCompletionUsageCompletionTokensDetails,
    OpenAIChatCompletionUsagePromptTokensDetails,
    OpenAIChoice,
    OpenAIChoiceDelta,
    OpenAIChoiceLogprobs,
    OpenAIChunkChoice,
    OpenAICompletion,
    OpenAICompletionChoice,
    OpenAICompletionLogprobs,
    OpenAICompletionRequestWithExtraBody,
    OpenAICompletionWithInputMessages,
    OpenAIDeveloperMessageParam,
    OpenAIEmbeddingData,
    OpenAIEmbeddingsRequestWithExtraBody,
    OpenAIEmbeddingsResponse,
    OpenAIEmbeddingUsage,
    OpenAIFile,
    OpenAIFileFile,
    OpenAIFinishReason,
    OpenAIImageURL,
    OpenAIJSONSchema,
    OpenAIMessageParam,
    OpenAIResponseFormatJSONObject,
    OpenAIResponseFormatJSONSchema,
    OpenAIResponseFormatParam,
    OpenAIResponseFormatText,
    OpenAISystemMessageParam,
    OpenAITokenLogProb,
    OpenAIToolMessageParam,
    OpenAITopLogProb,
    OpenAIUserMessageParam,
    QuantizationConfig,
    QuantizationType,
    RerankData,
    RerankRequest,
    RerankResponse,
    ResponseFormat,
    ResponseFormatType,
    SamplingParams,
    SamplingStrategy,
    SystemMessage,
    SystemMessageBehavior,
    TextTruncation,
    TokenLogProbs,
    ToolChoice,
    ToolResponseMessage,
    TopKSamplingStrategy,
    TopPSamplingStrategy,
    UserMessage,
)

__all__ = [
    # Protocol
    "Inference",
    "InferenceProvider",
    "ModelStore",
    # Common types (for backward compatibility)
    "InterleavedContent",
    # Sampling
    "GreedySamplingStrategy",
    "TopPSamplingStrategy",
    "TopKSamplingStrategy",
    "SamplingStrategy",
    "SamplingParams",
    "LogProbConfig",
    # Quantization
    "QuantizationType",
    "Fp8QuantizationConfig",
    "Bf16QuantizationConfig",
    "Int4QuantizationConfig",
    "QuantizationConfig",
    # Messages
    "UserMessage",
    "SystemMessage",
    "ToolResponseMessage",
    "ToolChoice",
    "TokenLogProbs",
    # Response
    "ChatCompletionResponseEventType",
    "ResponseFormatType",
    "JsonSchemaResponseFormat",
    "GrammarResponseFormat",
    "ResponseFormat",
    "CompletionRequest",
    "SystemMessageBehavior",
    "EmbeddingsResponse",
    "RerankData",
    "RerankResponse",
    # OpenAI Compatibility
    "OpenAIChatCompletionContentPartTextParam",
    "OpenAIImageURL",
    "OpenAIChatCompletionContentPartImageParam",
    "OpenAIFileFile",
    "OpenAIFile",
    "OpenAIChatCompletionContentPartParam",
    "OpenAIChatCompletionMessageContent",
    "OpenAIChatCompletionTextOnlyMessageContent",
    "OpenAIUserMessageParam",
    "OpenAISystemMessageParam",
    "OpenAIChatCompletionToolCallFunction",
    "OpenAIChatCompletionToolCall",
    "OpenAIAssistantMessageParam",
    "OpenAIToolMessageParam",
    "OpenAIDeveloperMessageParam",
    "OpenAIMessageParam",
    "OpenAIResponseFormatText",
    "OpenAIJSONSchema",
    "OpenAIResponseFormatJSONSchema",
    "OpenAIResponseFormatJSONObject",
    "OpenAIResponseFormatParam",
    "FunctionToolConfig",
    "OpenAIChatCompletionToolChoiceFunctionTool",
    "CustomToolConfig",
    "OpenAIChatCompletionToolChoiceCustomTool",
    "AllowedToolsConfig",
    "OpenAIChatCompletionToolChoiceAllowedTools",
    "OpenAIChatCompletionToolChoice",
    "OpenAITopLogProb",
    "OpenAITokenLogProb",
    "OpenAIChoiceLogprobs",
    "OpenAIChoiceDelta",
    "OpenAIChunkChoice",
    "OpenAIChoice",
    "OpenAIChatCompletionUsageCompletionTokensDetails",
    "OpenAIChatCompletionUsagePromptTokensDetails",
    "OpenAIChatCompletionUsage",
    "OpenAIChatCompletion",
    "OpenAIChatCompletionChunk",
    "OpenAICompletionLogprobs",
    "OpenAICompletionChoice",
    "OpenAICompletion",
    "OpenAIFinishReason",
    "OpenAIEmbeddingData",
    "OpenAIEmbeddingUsage",
    "OpenAIEmbeddingsResponse",
    "TextTruncation",
    "EmbeddingTaskType",
    "OpenAICompletionWithInputMessages",
    "ListOpenAIChatCompletionResponse",
    "OpenAICompletionRequestWithExtraBody",
    "OpenAIChatCompletionRequestWithExtraBody",
    "OpenAIEmbeddingsRequestWithExtraBody",
    # Request Models
    "ListChatCompletionsRequest",
    "GetChatCompletionRequest",
    "RerankRequest",
    # Router factory module
    "fastapi_routes",
]
